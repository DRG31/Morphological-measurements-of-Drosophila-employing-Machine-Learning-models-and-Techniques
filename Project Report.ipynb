{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error , r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "# Task 1: Data Preparation\n",
    "\n",
    "# Load the 5 data files into separate dataframes\n",
    "df83 = pd.read_csv('83_Loeschcke_et_al_2000_Thorax_&_wing_traits_lab pops.csv')\n",
    "df84 = pd.read_csv('84_Loeschcke_et_al_2000_Wing_traits_&_asymmetry_lab pops.csv')\n",
    "df85 = pd.read_csv('85_Loeschcke_et_al_2000_Wing_asymmetry_lab_pops (1).csv')\n",
    "\n",
    "plot_dir = 'plots'\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "for tdf in [df83, df84, df85]:\n",
    "  for column in tdf.columns:\n",
    "    if pd.api.types.is_numeric_dtype(tdf[column]):\n",
    "     mean_value = tdf[column][tdf[column] != 0].mean()\n",
    "     tdf[column] = tdf[column].replace(0, mean_value)\n",
    "     tdf[column].fillna(mean_value, inplace=True)\n",
    "\n",
    "df83.info()\n",
    "df84.info()\n",
    "df85.info()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Preprocess the 'Species' column to have a consistent format\n",
    "df83['Species'] = df83['Species'].str.replace('D._', 'D.', regex=True)\n",
    "df85['Species'] = df85['Species'].str.replace('D._', 'D.', regex=True)\n",
    "\n",
    "common_cols = ['Species', 'Population', 'Latitude', 'Longitude', 'Year_start', 'Year_end', 'Temperature', 'Vial', 'Replicate', 'Sex']\n",
    "\n",
    "# Merge the DataFrames based on common columns\n",
    "merged_df = pd.merge(df83, df84[common_cols + ['Wing_area', 'Wing_shape', 'Wing_vein', 'Asymmetry_wing_area', 'Asymmetry_wing_shape', 'Asymmetry_wing_vein']], on=common_cols, how='left')\n",
    "\n",
    "merged_df = pd.merge(merged_df, df85[common_cols + ['Asymmetry_l2', 'Asymmetry_l3p', 'Asymmetry_l3d', 'Asymmetry_lpd', 'Asymmetry_l3', 'Asymmetry_w1', 'Asymmetry_w2', 'Asymmetry_w3']], on=common_cols, how='left')\n",
    "\n",
    "for column in merged_df.columns:\n",
    "    if pd.api.types.is_numeric_dtype(merged_df[column]):\n",
    "     mean_value = merged_df[column][merged_df[column] != 0].mean()\n",
    "     merged_df[column] = merged_df[column].replace(0, mean_value)\n",
    "     merged_df[column].fillna(mean_value, inplace=True)\n",
    "\n",
    "merged_df.info()\n",
    "\n",
    "# Display the merged DataFrame\n",
    "print(merged_df)\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Construct the file path for the merged data CSV file\n",
    "merged_data_file = os.path.join(current_dir, 'merged_data.csv')\n",
    "\n",
    "# Save the merged DataFrame to the CSV file, replacing if it already exists\n",
    "merged_df.to_csv(merged_data_file, index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Feature Selection and Data Preparation\n",
    "columns_for_eda = ['Latitude', 'Longitude','Temperature', 'Thorax_length', 'l2', 'l3p', 'l3d', 'lpd', 'l3', 'w1', 'w2', 'w3', 'wing_loading', 'Wing_area', 'Asymmetry_wing_area', 'Asymmetry_wing_vein', 'Asymmetry_l3p', 'Asymmetry_lpd', 'Asymmetry_l3']\n",
    "\n",
    "for col in merged_df[columns_for_eda].columns:\n",
    "    merged_df[col] = pd.to_numeric(merged_df[col], errors='coerce')\n",
    "\n",
    "def analyze_correlation_heatmap(corr_matrix, threshold=0.7):\n",
    "    analysis = \"\"\n",
    "    columns = corr_matrix.columns\n",
    "\n",
    "    for i in range(len(columns)):\n",
    "        for j in range(i+1, len(columns)):\n",
    "            col1 = columns[i]\n",
    "            col2 = columns[j]\n",
    "            corr_value = corr_matrix.iloc[i, j]\n",
    "\n",
    "            if threshold <= corr_value < 1:\n",
    "                description = \"strong positive correlation\"\n",
    "                analysis += f\"There is a {description} ({corr_value:.2f}) between '{col1}' and '{col2}'.\\n\"\n",
    "\n",
    "    if not analysis:\n",
    "        analysis = f\"No strong correlations (above {threshold}) were found in the data.\"\n",
    "\n",
    "    return analysis\n",
    "\n",
    "# Generate correlation heatmap\n",
    "correlation_matrix = merged_df[columns_for_eda].corr()\n",
    "plt.figure(figsize=(18, 15))\n",
    "heatmap = sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", annot_kws={\"size\": 10})\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.yticks(rotation=0)\n",
    "plt.title('Correlation Heatmap', fontsize=30)\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_heatmap.png', dpi=1024)\n",
    "plt.show()\n",
    "\n",
    "analysis = analyze_correlation_heatmap(correlation_matrix, threshold=0.7)\n",
    "print(analysis)\n",
    "\n",
    "# Plot histogram for selected columns\n",
    "histogram_columns = ['Thorax_length', 'l2', 'l3p', 'l3d', 'lpd', 'l3', 'w1', 'w2', 'w3', 'wing_loading', 'Wing_area']\n",
    "for col in histogram_columns:\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    merged_df[col].hist(ax=ax, bins=20)\n",
    "    ax.set_title(f'Histogram of {col}')\n",
    "    ax.set_xlabel(col)\n",
    "    ax.set_ylabel('Count')\n",
    "    plt.tight_layout()\n",
    "    hist_file = os.path.join(plot_dir, f'histogram_{col}.png')\n",
    "    plt.savefig(hist_file, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sex_counts = merged_df['Sex'].value_counts()\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "sex_counts.plot(kind='bar', ax=ax, rot=0)\n",
    "ax.set_title('Distribution of Sex')\n",
    "ax.set_xlabel('Sex')\n",
    "ax.set_ylabel('Count')\n",
    "plt.tight_layout()\n",
    "bar_plot_file = os.path.join(plot_dir, 'sex_bar_plot.png')\n",
    "plt.savefig(bar_plot_file, dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Bar plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.countplot(data=merged_df, x='Population')\n",
    "plt.title('Bar Plot of Population')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Density plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.kdeplot(data=merged_df['Temperature'], fill=True)\n",
    "plt.title('Density Plot of Temperature')\n",
    "plt.xlabel('Temperature')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot matrix\n",
    "columns = ['Thorax_length', 'l2', 'l3p', 'l3d', 'lpd', 'l3', 'w1', 'w2', 'w3', 'wing_loading', 'Wing_area']\n",
    "selected_df = merged_df[columns]\n",
    "\n",
    "scatter_matrix = pd.plotting.scatter_matrix(selected_df, figsize=(15, 15))\n",
    "plt.suptitle('Scatter Plot Matrix of Variables', x=0.5, y=0.92)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "target_column = ['Thorax_length', 'l2', 'l3p', 'l3d', 'lpd', 'l3', 'w1', 'w2', 'w3', 'wing_loading', 'Wing_area', 'Asymmetry_wing_area', 'Asymmetry_wing_vein', 'Asymmetry_l3p', 'Asymmetry_lpd', 'Asymmetry_l3']\n",
    "\n",
    "target = ['Thorax_length', 'l2', 'lpd', 'l3', 'w1', 'w2', 'w3', 'wing_loading', 'Wing_area']\n",
    "\n",
    "df = merged_df[target_column]\n",
    "\n",
    "# Convert columns to numeric, coercing errors to NaN\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Drop rows with NaNs in any target column\n",
    "df.dropna(subset=target, inplace=True)\n",
    "\n",
    "y = df[target]\n",
    "X = df\n",
    "\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=250)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=250)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"KNN\": KNeighborsRegressor(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "    \"SVR\": MultiOutputRegressor(SVR()),\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"MLP\": MLPRegressor(max_iter=5000)\n",
    "}\n",
    "\n",
    "# Define hyperparameters for grid search\n",
    "params = {\n",
    "    \"KNN\": {'n_neighbors': range(1, 21)},\n",
    "    \"Decision Tree\": {'max_depth': range(1, 21)},\n",
    "    \"Random Forest\": {'n_estimators': [10, 50, 100, 200], 'max_depth': range(1, 21)},\n",
    "    \"SVR\": {'estimator__C': [0.1, 1, 10], 'estimator__kernel': ['linear', 'rbf']},\n",
    "    \"Linear Regression\": {},\n",
    "    \"MLP\": {'hidden_layer_sizes': [(10,), (50,), (100,)], 'alpha': [0.0001, 0.001, 0.01]}\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    grid_search = GridSearchCV(model, params[name], cv=5, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred_train = best_model.predict(X_train)\n",
    "    y_pred_val = best_model.predict(X_val)\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    mse_val = mean_squared_error(y_val, y_pred_val)\n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "    r2_val = r2_score(y_val, y_pred_val)\n",
    "    results[name] = {\"best_model\": best_model, \"mse_train\": mse_train, \"mse_val\": mse_val, \"r2_train\": r2_train, \"r2_val\": r2_val}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compare performance\n",
    "for name, result in results.items():\n",
    "    print(f\"{name}: MSE (Train) = {result['mse_train']}, MSE (Val) = {result['mse_val']}, R^2 (Train) = {result['r2_train']}, R^2 (Val) = {result['r2_val']}\")\n",
    "\n",
    "colors = ['blue', 'green', 'red', 'purple', 'orange', 'yellow']\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(results.keys(), [result['mse_val'] for result in results.values()], color=colors)\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_performance_comparison.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(results.keys(), [result['r2_val'] for result in results.values()], color=colors)\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('R² Value')\n",
    "plt.title('Model Performance Comparison - R²')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_performance_comparison_r2.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for name, result in results.items():\n",
    "    model = result[\"best_model\"]\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    # Plotting for each target variable\n",
    "    for target in y_test.columns:  # Iterate over column names\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        ax.scatter(y_test[target], y_pred_test[:, y_test.columns.get_loc(target)], alpha=0.5)\n",
    "        ax.set_xlabel(f'Actual {target}')\n",
    "        ax.set_ylabel(f'Predicted {target}')\n",
    "        ax.set_title(f'{name}: Actual vs Predicted {target}')\n",
    "        fig.savefig(f'{name}_{target}_actual_vs_predicted.png', bbox_inches='tight')\n",
    "        plt.show()\n",
    "        plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define a wider range of hyperparameters for KNN\n",
    "params_knn = {'n_neighbors': range(1, 51), 'weights': ['uniform', 'distance'], 'p': [1, 2]}\n",
    "\n",
    "# Perform grid search with the extended parameter grid\n",
    "grid_search_knn = GridSearchCV(KNeighborsRegressor(), params_knn, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search_knn.fit(X_train, y_train)\n",
    "\n",
    "# Get the best KNN model\n",
    "knn_best_extended = grid_search_knn.best_estimator_\n",
    "\n",
    "# Define a wider range of hyperparameters for MLP\n",
    "params_mlp = {'hidden_layer_sizes': [(10,), (50,), (100,), (10, 10), (50, 50), (100, 100)], 'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "# Perform grid search with the extended parameter grid\n",
    "grid_search_mlp = GridSearchCV(MLPRegressor(max_iter=2000), params_mlp, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search_mlp.fit(X_train, y_train)\n",
    "\n",
    "# Get the best MLP model\n",
    "mlp_best_extended = grid_search_mlp.best_estimator_\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X_train)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Define MSE values for existing models\n",
    "existing_models_mse = {}\n",
    "\n",
    "for name, result in results.items():\n",
    "    existing_models_mse[name] = result['mse_val']\n",
    "\n",
    "tuned_models_mse = {\n",
    "    \"KNN (Tuned)\": abs(grid_search_knn.best_score_),\n",
    "    \"MLP (Tuned)\": abs(grid_search_mlp.best_score_),\n",
    "}\n",
    "\n",
    "\n",
    "# Combine MSE values for both existing and tuned models\n",
    "all_models_mse = {**existing_models_mse, **tuned_models_mse}\n",
    "\n",
    "# Create a bar plot to compare MSE values for all models\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(all_models_mse.keys(), all_models_mse.values(), color=['blue' if model.endswith('(Tuned)') else 'green' for model in all_models_mse.keys()])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Model Performance Comparison Before and After Tuning')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Perform PCA\n",
    "pca = PCA(n_components=5)\n",
    "X_pca = pca.fit_transform(X_train)  # Fit PCA on training data\n",
    "\n",
    "# Plot explained variance ratio\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), np.cumsum(pca.explained_variance_ratio_), marker='o')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance Ratio')\n",
    "plt.title('Cumulative Explained Variance by Principal Components')\n",
    "plt.show()\n",
    "\n",
    "# Train models on PCA-transformed data\n",
    "results_pca = {}\n",
    "for name, model in models.items():\n",
    "    grid_search = GridSearchCV(model, params[name], cv=5, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X_pca, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    y_pred_train = best_model.predict(X_pca)\n",
    "    y_pred_val = best_model.predict(pca.transform(X_val))  # Transform validation data using the same PCA\n",
    "\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    mse_val = mean_squared_error(y_val, y_pred_val)\n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "    r2_val = r2_score(y_val, y_pred_val)\n",
    "\n",
    "    results_pca[name] = {\"best_model\": best_model, \"mse_train\": mse_train, \"mse_val\": mse_val, \"r2_train\": r2_train, \"r2_val\": r2_val}\n",
    "\n",
    "# Print results with PCA\n",
    "for name, result in results_pca.items():\n",
    "    print(f\"{name} Results (with PCA):\")\n",
    "    print(f\"  MSE (Train): {result['mse_train']:.4f}\")\n",
    "    print(f\"  MSE (Validation): {result['mse_val']:.4f}\")\n",
    "    print(f\"  R-squared (Train): {result['r2_train']:.4f}\")\n",
    "    print(f\"  R-squared (Validation): {result['r2_val']:.4f}\")\n",
    "    print()\n",
    "\n",
    "colors = ['blue', 'green', 'red', 'purple', 'orange', 'yellow']\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(results_pca.keys(), [result['mse_val'] for result in results_pca.values()], color=colors)\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_performance_comparison.png')\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "model_names = list(results_pca.keys())\n",
    "# Extract MSE and R2 values for models with and without PCA\n",
    "mse_val_pca = [result['mse_val'] for result in results_pca.values()]\n",
    "r2_val_pca = [result['r2_val'] for result in results_pca.values()]\n",
    "mse_val_no_pca = [results[model]['mse_val'] for model in model_names]\n",
    "r2_val_no_pca = [results[model]['r2_val'] for model in model_names]\n",
    "\n",
    "bar_width = 0.35\n",
    "index = np.arange(len(model_names))\n",
    "\n",
    "# Plotting MSE comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(index, mse_val_no_pca, bar_width, label='Without PCA', color=colors)\n",
    "plt.bar(index + bar_width, mse_val_pca, bar_width, label='With PCA', color=[plt.cm.Paired(i/len(colors)) for i in range(len(colors))])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Model Performance Comparison (MSE)')\n",
    "plt.xticks(index + bar_width / 2, model_names, rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_performance_comparison_mse.png')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R2 comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(index, r2_val_no_pca, bar_width, label='Without PCA', color=colors)\n",
    "plt.bar(index + bar_width, r2_val_pca, bar_width, label='With PCA', color=[plt.cm.Paired(i/len(colors)) for i in range(len(colors))])\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('R² Score')\n",
    "plt.title('Model Performance Comparison (R²)')\n",
    "plt.xticks(index + bar_width / 2, model_names, rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_performance_comparison_r2.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown']\n",
    "\n",
    "# Extract results from results_pca dictionary\n",
    "mse_train = [results_pca[name]['mse_train'] for name in models]\n",
    "mse_val = [results_pca[name]['mse_val'] for name in models]\n",
    "r2_train = [results_pca[name]['r2_train'] for name in models]\n",
    "r2_val = [results_pca[name]['r2_val'] for name in models]\n",
    "\n",
    "# Plot MSE\n",
    "plt.figure(figsize=(10, 6))\n",
    "bar_width = 0.35\n",
    "index = np.arange(len(models))\n",
    "plt.bar(index, mse_train, bar_width, color=[colors[i] for i in range(len(models))], alpha=0.5, label='Train')\n",
    "plt.bar(index + bar_width, mse_val, bar_width, color=[colors[i] for i in range(len(models))], alpha=0.8, label='Validation')\n",
    "plt.xticks(index + bar_width / 2, models, rotation=45, ha='right')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Mean Squared Error (Train vs Validation)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/mse_plot.png')\n",
    "plt.show()\n",
    "\n",
    "# Plot R-squared\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(index, r2_train, bar_width, color=[colors[i] for i in range(len(models))], alpha=0.5, label='Train')\n",
    "plt.bar(index + bar_width, r2_val, bar_width, color=[colors[i] for i in range(len(models))], alpha=0.8, label='Validation')\n",
    "plt.xticks(index + bar_width / 2, models, rotation=45, ha='right')\n",
    "plt.ylabel('R-squared')\n",
    "plt.title('R-squared (Train vs Validation)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/r2_plot.png')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
